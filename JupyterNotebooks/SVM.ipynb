{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(train_X[5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape datasets, create toy model for initial experimentation \n",
    "POC = train_X[0:599]\n",
    "num,d1,d2 = POC.shape\n",
    "POC = POC.reshape((num, d1 * d2))\n",
    "POC_lbl = train_y[0:599]\n",
    "\n",
    "POC_tst = train_X[400:599]\n",
    "num,d1,d2 = POC_tst.shape\n",
    "POC_tst = POC_tst.reshape((num, d1 * d2))\n",
    "POC_lbl_tst = train_y[400:599]\n",
    "\n",
    "num,d1,d2 = train_X.shape\n",
    "train_X_transform = train_X.reshape((num, d1*d2))\n",
    "num,d1,d2 = test_X.shape\n",
    "test_X_transform = test_X.reshape((num, d1*d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 regularization, squared hinge loss:  0.9165\n",
      "l2 regularization, squared hinge loss:  0.9181\n"
     ]
    }
   ],
   "source": [
    "# use l1 regularization for linear SVC\n",
    "svm_model = svm.LinearSVC(penalty='l1', loss='squared_hinge', dual=False, tol=0.001, C=1)\n",
    "svm_model.fit(train_X_transform,train_y)\n",
    "score = svm_model.score(test_X_transform, test_y)\n",
    "print('l1 regularization, squared hinge loss: ', score)\n",
    "\n",
    "# use l2 regularization and squared hinge loss\n",
    "svm_model = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=False, tol=0.001, C=1)\n",
    "svm_model.fit(train_X_transform,train_y)\n",
    "score = svm_model.score(test_X_transform, test_y)\n",
    "print('l2 regularization, squared hinge loss: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nealdesai/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nealdesai/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nealdesai/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n",
      "0.826\n",
      "C =  0.01 , Accuracy =  0.844\n",
      "C =  0.1 , Accuracy =  0.814\n",
      "C =  1 , Accuracy =  0.825\n",
      "C =  10 , Accuracy =  0.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nealdesai/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Regularization Parameter Tests\n",
    "CVals = [0.01, 0.1, 1, 10]\n",
    "l1Scores = []\n",
    "\n",
    "for i in range(len(CVals)):\n",
    "    # use l1 regularization for linear SVC\n",
    "    svm_model = svm.LinearSVC(penalty='l1', loss='squared_hinge', dual=False, tol=0.001, C=CVals[i])\n",
    "    svm_model.fit(train_X_transform[0:5000],train_y[0:5000])\n",
    "    l1Scores.append(svm_model.score(test_X_transform[0:1000], test_y[0:1000]))\n",
    "    print(l1Scores[i])\n",
    "\n",
    "for i,e in enumerate(l1Scores):\n",
    "    print('C = ', CVals[i], ', Accuracy = ', l1Scores[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n",
      "0.808\n",
      "0.802\n",
      "0.797\n",
      "C =  0.01 , Accuracy =  0.81\n",
      "C =  0.1 , Accuracy =  0.808\n",
      "C =  1 , Accuracy =  0.802\n",
      "C =  10 , Accuracy =  0.797\n"
     ]
    }
   ],
   "source": [
    "l2Scores = []\n",
    "\n",
    "for i in range(len(CVals)):\n",
    "    # use l2 regularization for linear SVC\n",
    "    svm_model = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=False, tol=0.001, C=CVals[i])\n",
    "    svm_model.fit(train_X_transform[0:5000],train_y[0:5000])\n",
    "    l2Scores.append(svm_model.score(test_X_transform[0:1000], test_y[0:1000]))\n",
    "    print(l2Scores[i])\n",
    "\n",
    "for i,e in enumerate(l2Scores):\n",
    "    print('C = ', CVals[i], ', Accuracy = ', l2Scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 regularization, squared hinge loss:  0.9179\n",
      "l2 regularization, squared hinge loss:  0.9175\n"
     ]
    }
   ],
   "source": [
    "# use l1 regularization for linear SVC\n",
    "svm_model = svm.LinearSVC(penalty='l1', loss='squared_hinge', dual=False, tol=0.001, C=0.01)\n",
    "svm_model.fit(train_X_transform,train_y)\n",
    "score = svm_model.score(test_X_transform, test_y)\n",
    "print('l1 regularization, squared hinge loss: ', score)\n",
    "\n",
    "# use l2 regularization and squared hinge loss\n",
    "svm_model = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=False, tol=0.001, C=0.01)\n",
    "svm_model.fit(train_X_transform,train_y)\n",
    "score = svm_model.score(test_X_transform, test_y)\n",
    "print('l2 regularization, squared hinge loss: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545\n",
      "0.89\n",
      "0.936\n",
      "0.945\n",
      "0.945\n",
      "C =  0.01 , Accuracy =  0.545\n",
      "C =  0.1 , Accuracy =  0.89\n",
      "C =  1 , Accuracy =  0.936\n",
      "C =  10 , Accuracy =  0.945\n",
      "C =  100 , Accuracy =  0.945\n"
     ]
    }
   ],
   "source": [
    "# Regularization Parameter Tests\n",
    "CVals = [0.01, 0.1, 1, 10, 100]\n",
    "rbfScores = []\n",
    "\n",
    "for i in range(len(CVals)):\n",
    "    # use l1 regularization for linear SVC\n",
    "    svm_model = svm.SVC(C = CVals[i], kernel='rbf')\n",
    "    svm_model.fit(train_X_transform[0:5000],train_y[0:5000])\n",
    "    rbfScores.append(svm_model.score(test_X_transform[0:1000], test_y[0:1000]))\n",
    "    print(rbfScores[i])\n",
    "\n",
    "for i,e in enumerate(rbfScores):\n",
    "    print('C = ', CVals[i], ', Accuracy = ', rbfScores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n",
      "0.83\n",
      "0.919\n",
      "0.926\n",
      "0.928\n",
      "C =  0.01 , Accuracy =  0.48\n",
      "C =  0.1 , Accuracy =  0.83\n",
      "C =  1 , Accuracy =  0.919\n",
      "C =  10 , Accuracy =  0.926\n",
      "C =  100 , Accuracy =  0.928\n"
     ]
    }
   ],
   "source": [
    "# Regularization Parameter Tests\n",
    "CVals = [0.01, 0.1, 1, 10, 100]\n",
    "polyScores = []\n",
    "\n",
    "for i in range(len(CVals)):\n",
    "    # use l1 regularization for linear SVC\n",
    "    svm_model = svm.SVC(C = CVals[i], kernel='poly')\n",
    "    svm_model.fit(train_X_transform[0:5000],train_y[0:5000])\n",
    "    polyScores.append(svm_model.score(test_X_transform[0:1000], test_y[0:1000]))\n",
    "    print(polyScores[i])\n",
    "\n",
    "for i,e in enumerate(polyScores):\n",
    "    print('C = ', CVals[i], ', Accuracy = ', polyScores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on n=5000 subset, our ideal hyperparameters are rbf kernel with a regularization constant C=10. Let's now try this on the entire 60,000 sample training set and validate on the full testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9837\n"
     ]
    }
   ],
   "source": [
    "optimal_model = svm.SVC(C = 10, kernel='rbf')\n",
    "optimal_model.fit(train_X_transform, train_y)\n",
    "optimal_score = optimal_model.score(test_X_transform, test_y)\n",
    "print(optimal_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
